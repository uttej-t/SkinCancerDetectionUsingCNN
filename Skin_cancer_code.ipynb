# -*- coding: utf-8 -*-
"""Skin Cancer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RzxkOM_WILI8dB2ECYe_NaVIhDcxMXjc
"""

from io import BytesIO
import numpy as np
from pyspark import SparkContext
import pandas as pd
from PIL import Image
import os
from keras.utils.np_utils import to_categorical
from keras.models import Sequential, Model
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D
from keras import backend as K
from keras.layers.normalization import BatchNormalization
from keras.optimizers import Adam, RMSprop
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ReduceLROnPlateau
from keras.wrappers.scikit_learn import KerasClassifier
from keras.applications.resnet50 import ResNet50
from keras import backend as K 

from pyspark.sql import SparkSession

def mapFunc(arg):
    #lambda img : [i, np.array(Image.open(img[1]).convert('RGB'),dtype='uint8')]
    '''
        i = 0, for Training - Benign image
        i = 1, for Training - Malignant image
        i = 2, for Test - Benign image
        i = 3, for Test - Malignant image
    '''
    #Converting Image to RGB
    image_arr = np.array(Image.open(BytesIO(arg[1])).convert("RGB"),dtype='uint8')

    path = arg[0]

    i = ( (0 if 'benign' in path else 1) if 'train' in path else (2 if 'benign' in path else 3) )
    
    conv_filter = np.random.randint(-1,2,(3,3,3))
    #print(conv_filter)
    stride = 1
    
    #print(image_arr,"\n\n\n\n")
    
    row = conv_filter.shape[0]
    col = conv_filter.shape[1]
    imgRows = image_arr.shape[0]
    imgCols = image_arr.shape[1]
    
    conv_List = [];
    #print(row,col,imgRows,imgCols)
    
    #print(image_arr[0,0])
    
    #Convolution
    while row <= imgRows:
        while  col <= imgCols:
            #print(stride,row,col)
            #print(image_arr[row+stride-1 : col+stride-1:3],"\n\n\n\n")
            conv_List.append(np.dot(image_arr[row+stride-1 : col+stride-1 : 3],conv_filter))
            col += 1
        row += 1
    #Relu
    
    return (i,np.array(conv_List))
        

def reduceFunc(key, value):
    if True == False:
        #Shuffling data
        s = np.arange(value.shape[0])
        np.random.shuffle(s)

        #( DataType_Cancer_Type, (Y, X)) --DataType = Train/Test
        if key == 0:
            X_benign.append(value)
            Y_benign.append(np.zeros(value.shape[0]))
        elif key == 1:
            X_malignant.append(value)
            Y_malignant.append(np.zeros(value.shape[0]))
        elif key == 2:
            X_benign_test.append(value)
            Y_benign_test.append(np.zeros(value.shape[0]))
        elif key == 3:
            X_malignant_test.append(value)
            Y_malignant_test.append(np.zeros(value.shape[0]))
    
    return value

def main(): 
    X_benign = list();
    Y_benign = list();
    X_malignant = list();
    Y_malignant = list();

    X_benign_test = list();
    Y_benign_test = list();
    X_malignant_test = list();
    Y_malignant_test = list();

    np.random.seed(1102)

    #Getting Spark context
    sc = SparkContext().getOrCreate('SparkWordCount')

    #Dataset folders
    folder_Benign_Train = "/home/uttejt/Downloads/train/benign"
    folder_Benign_Test = "/home/uttejt/Downloads/test/benign"
    folder_Malignant_Train = "/home/uttejt/Downloads/train/malignant"
    folder_Malignant_Test = "/home/uttejt/Downloads/test/malignant"

    folders_To_Read = ','.join([folder_Benign_Train,folder_Benign_Test,folder_Malignant_Train,folder_Malignant_Test])
    print(folders_To_Read)

    #reads files as text file
    #input_file = sc.wholeTextFiles(folders_To_Read, use_unicode = False)

    #reads image as binaryfile
    input_file = sc.binaryFiles(folders_To_Read)

    #for debugging:
    #folders_To_Read = '/content/drive/MyDrive/UMD/Big Data/Hadoop/Project/data/test/benign/1.jpg'
    #for input in input_file.take(100):
    #img = BytesIO(input[1])
    #print(img.__repr__())
    #print(input[0],np.array(Image.open(img).convert("RGB"),dtype = 'uint8'))
    
    counts = input_file.map(mapFunc).reduceByKey(reduceFunc)
    
    #print(counts)
    
    counts.saveAsTextFile('/home/hduser/output/')

    sc.stop()

if __name__ == '__main__':
    main()

